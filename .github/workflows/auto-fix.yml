name: Auto-Fix Test Failures

on:
  issues:
    types: [opened, labeled]
  workflow_dispatch:
    inputs:
      issue_number:
        description: 'Issue number to fix'
        required: true
        type: number
      ai_model:
        description: 'AI model to use'
        required: false
        default: 'gpt-4o-mini'
        type: choice
        options:
          - gpt-4o-mini
          - gpt-4o
          - claude-3-5-sonnet-20240620
          - deepseek/deepseek-chat
          - deepseek/deepseek-coder

jobs:
  attempt-auto-fix:
    name: Attempt Auto-Fix
    # Only run if issue has 'auto-fix-ready' label OR manual trigger
    if: |
      github.event_name == 'workflow_dispatch' ||
      contains(github.event.issue.labels.*.name, 'auto-fix-ready')
    runs-on: ubuntu-latest

    permissions:
      contents: write      # To create branches and commits
      issues: write        # To comment on issues
      pull-requests: write # To create PRs

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Get issue number
        id: issue
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "number=${{ inputs.issue_number }}" >> $GITHUB_OUTPUT
            echo "ai_model=${{ inputs.ai_model }}" >> $GITHUB_OUTPUT
          else
            echo "number=${{ github.event.issue.number }}" >> $GITHUB_OUTPUT
            echo "ai_model=gpt-4o-mini" >> $GITHUB_OUTPUT
          fi

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Run tests to generate failures
        id: tests
        run: |
          set +e  # Don't exit on test failure
          npm test
          TEST_EXIT_CODE=$?
          echo "exit-code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0  # Always succeed this step
        continue-on-error: true

      - name: Check if failures exist
        id: check_failures
        run: |
          if [ ! -f "playwright-report/results.json" ]; then
            echo "‚ùå No test results found"
            echo "failures_found=false" >> $GITHUB_OUTPUT
            exit 1
          fi

          # Check if there are actual failures in the results
          FAILURE_COUNT=$(jq '[.suites[].specs[].tests[] | select(.status == "failed" or .status == "timedOut")] | length' playwright-report/results.json)

          if [ "$FAILURE_COUNT" -eq 0 ]; then
            echo "‚úÖ No test failures found - nothing to fix!"
            echo "failures_found=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "üìä Found $FAILURE_COUNT test failures"
          echo "failures_found=true" >> $GITHUB_OUTPUT
          echo "failure_count=$FAILURE_COUNT" >> $GITHUB_OUTPUT

      - name: Skip if no failures
        if: steps.check_failures.outputs.failures_found != 'true'
        run: |
          echo "No failures to fix - exiting gracefully"
          gh issue comment ${{ steps.issue.outputs.number }} --body "## ‚ÑπÔ∏è No Failures Found

          Re-ran tests but found no failures to fix. The tests may have been fixed already or the issue may be resolved.

          ü§ñ Auto-Fix Workflow"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Dagger
        uses: dagger/dagger-for-github@v6
        with:
          version: "latest"

      - name: Run Dagger auto-fix
        if: steps.check_failures.outputs.failures_found == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          # AI API keys - at least one must be set
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          echo "üöÄ Starting Dagger auto-fix..."
          echo "   Issue: #${{ steps.issue.outputs.number }}"
          echo "   Model: ${{ steps.issue.outputs.ai_model }}"
          echo "   Failures: ${{ steps.check_failures.outputs.failure_count }}"

          dagger -m dagger call fix-and-create-pr \
            --repo-dir=. \
            --failures-json-path=playwright-report/results.json \
            --issue-number=${{ steps.issue.outputs.number }} \
            --github-token=env:GITHUB_TOKEN \
            --ai-model=${{ steps.issue.outputs.ai_model }} \
            --min-confidence=0.75 \
            --repository=${{ github.repository }} \
            --base-branch=main \
            --openai-api-key=env:OPENAI_API_KEY \
            --anthropic-api-key=env:ANTHROPIC_API_KEY \
            --deepseek-api-key=env:DEEPSEEK_API_KEY

      - name: Upload test results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ steps.issue.outputs.number }}
          path: |
            playwright-report/
            test-results/
          retention-days: 7

      - name: Comment on issue if failed
        if: failure()
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh issue comment ${{ steps.issue.outputs.number }} --body "## ‚ùå Auto-Fix Failed

          The auto-fix workflow encountered an error and could not complete.

          **Troubleshooting:**
          - Check that the issue contains valid failure JSON from the Playwright Failure Analyzer
          - Verify that AI API keys are configured in repository secrets
          - Review the workflow logs for detailed error messages

          [View workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ü§ñ Auto-Fix Workflow"
